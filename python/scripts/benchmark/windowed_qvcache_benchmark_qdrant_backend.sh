#!/bin/bash

# Script to run windowed QVCache benchmark experiment with noisy queries using Qdrant backend
# This script uses the noisy queries generated by generate_noisy_queries.py
# and runs the windowed_qvcache_benchmark_qdrant_backend.py experiment with window-based processing

set -e

# Change to project root
cd "$(dirname "$0")/../../.." || exit 1

# Define variables
DATASET="deep10m"
DATA_TYPE="float"
DATA_PATH="data/$DATASET/${DATASET}_base.bin"

# Noisy query parameters
N_SPLIT=10
N_SPLIT_REPEAT=30
NOISE_RATIO=0.01

# Window parameters
WINDOW_SIZE=4
N_REPEAT=3
STRIDE=1
N_ROUND=1

# Construct query and groundtruth paths based on noisy query parameters
# Format noise_ratio to match Python script (remove trailing zeros)
NOISE_STR=$(echo "$NOISE_RATIO" | sed 's/\.0*$//;s/\.$//')
QUERY_PATH="data/$DATASET/${DATASET}_query_nsplit-${N_SPLIT}_nrepeat-${N_SPLIT_REPEAT}_noise-${NOISE_STR}.bin"
GROUNDTRUTH_PATH="data/$DATASET/${DATASET}_groundtruth_nsplit-${N_SPLIT}_nrepeat-${N_SPLIT_REPEAT}_noise-${NOISE_STR}.bin"

# QVCache parameters
R=64
MEMORY_L=32  
K=10
B=8
M=8
ALPHA=1.2
SEARCH_THREADS=24
BUILD_THREADS=8
BEAMWIDTH=2
USE_RECONSTRUCTED_VECTORS=0
P=0.90
DEVIATION_FACTOR=0.075
USE_REGIONAL_THETA=1 # Set to 0 to use global theta instead of regional theta
PCA_DIM=16 # Set to desired PCA dimension (e.g., 16)
BUCKETS_PER_DIM=8 # Set to desired number of buckets per PCA dimension (e.g., 4)
MEMORY_INDEX_MAX_POINTS=60000 # Set to desired max points for memory index
MAX_REGIONS=1000000 # Maximum number of regions for regional theta (default: unlimited = max size_t, set to a specific number to limit)
N_ASYNC_INSERT_THREADS=4 # Number of async insert threads
LAZY_THETA_UPDATES=1 # Set to 1 to enable lazy theta updates, 0 for immediate updates
NUMBER_OF_MINI_INDEXES=4 # Number of mini indexes for shadow cycling
SEARCH_MINI_INDEXES_IN_PARALLEL=false # Set to true to search mini indexes in parallel
MAX_SEARCH_THREADS=32 # Maximum threads for parallel search
SEARCH_STRATEGY="SEQUENTIAL_LRU_ADAPTIVE" # Search strategy: SEQUENTIAL_LRU_STOP_FIRST_HIT, SEQUENTIAL_LRU_ADAPTIVE, SEQUENTIAL_ALL, PARALLEL
METRIC="l2" # Distance metric: "l2", "cosine", or "inner_product"

# Qdrant backend parameters
COLLECTION_NAME="vectors"

# Detect if running inside Docker and set Qdrant URL accordingly
if [ -f /.dockerenv ] || [ -n "$DOCKER_CONTAINER" ]; then
    QDRANT_URL="http://qdrant:6333"  # Docker internal network
else
    QDRANT_URL="http://localhost:6333"  # Local machine
fi

# Allow override via environment variable
if [ -n "$QDRANT_URL_ENV" ]; then
    QDRANT_URL="$QDRANT_URL_ENV"
fi

PCA_PREFIX="./index/${DATASET}/${DATASET}"

# Validate window parameters
MIN_SPLIT_REPEAT=$(( (WINDOW_SIZE / STRIDE) * N_REPEAT * N_ROUND ))
if [ "$N_SPLIT_REPEAT" -lt "$MIN_SPLIT_REPEAT" ]; then
    echo "Error: n_split_repeat ($N_SPLIT_REPEAT) must be >= (window_size / stride) * n_repeat * n_round = $MIN_SPLIT_REPEAT"
    exit 1
fi

# Check if query file exists
if [ ! -f "$QUERY_PATH" ]; then
    echo "Error: Query file not found: $QUERY_PATH"
    echo "Please run generate_noisy_queries.sh first to generate the query file."
    exit 1
fi

# Check if groundtruth file exists
if [ ! -f "$GROUNDTRUTH_PATH" ]; then
    echo "Error: Groundtruth file not found: $GROUNDTRUTH_PATH"
    echo "Please run generate_noisy_queries.sh first to generate the groundtruth file."
    exit 1
fi

# Activate virtual environment if it exists
if [ -d "venv" ]; then
    source venv/bin/activate
fi

# Add python directory to PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)/python"

echo "=========================================="
echo "Windowed QVCache Benchmark (Qdrant) - Noisy Queries"
echo "=========================================="
echo "Dataset: $DATASET"
echo "Query file: $QUERY_PATH"
echo "Groundtruth file: $GROUNDTRUTH_PATH"
echo "Noise parameters: n_split=$N_SPLIT, n_repeat=$N_SPLIT_REPEAT, noise_ratio=$NOISE_RATIO"
echo "Window parameters: window_size=$WINDOW_SIZE, n_repeat=$N_REPEAT, stride=$STRIDE, n_round=$N_ROUND"
echo "Qdrant: $QDRANT_URL, collection: $COLLECTION_NAME"
echo "=========================================="
echo ""

# Run the benchmark with all parameters and measure memory usage
# Monitor memory using /proc/<pid>/status VmHWM (High Water Mark)

# Start benchmark in background
python3 python/benchmarks/windowed_qvcache_benchmark_qdrant_backend.py \
  --data_path "$DATA_PATH" \
  --query_path "$QUERY_PATH" \
  --groundtruth_path "$GROUNDTRUTH_PATH" \
  --pca_prefix "$PCA_PREFIX" \
  --collection_name "$COLLECTION_NAME" \
  --qdrant_url "$QDRANT_URL" \
  --R "$R" \
  --memory_L "$MEMORY_L" \
  --K "$K" \
  --B "$B" \
  --M "$M" \
  --alpha "$ALPHA" \
  --build_threads "$BUILD_THREADS" \
  --search_threads "$SEARCH_THREADS" \
  --beamwidth "$BEAMWIDTH" \
  --use_reconstructed_vectors "$USE_RECONSTRUCTED_VECTORS" \
  --p "$P" \
  --deviation_factor "$DEVIATION_FACTOR" \
  --memory_index_max_points "$MEMORY_INDEX_MAX_POINTS" \
  --use_regional_theta "$USE_REGIONAL_THETA" \
  --pca_dim "$PCA_DIM" \
  --buckets_per_dim "$BUCKETS_PER_DIM" \
  --max_regions "$MAX_REGIONS" \
  --n_splits "$N_SPLIT" \
  --n_split_repeat "$N_SPLIT_REPEAT" \
  --n_async_insert_threads "$N_ASYNC_INSERT_THREADS" \
  --lazy_theta_updates "$LAZY_THETA_UPDATES" \
  --number_of_mini_indexes "$NUMBER_OF_MINI_INDEXES" \
  --search_mini_indexes_in_parallel "$SEARCH_MINI_INDEXES_IN_PARALLEL" \
  --max_search_threads "$MAX_SEARCH_THREADS" \
  --search_strategy "$SEARCH_STRATEGY" \
  --data_type "$DATA_TYPE" \
  --metric "$METRIC" \
  --window_size "$WINDOW_SIZE" \
  --n_repeat "$N_REPEAT" \
  --stride "$STRIDE" \
  --n_round "$N_ROUND" &

BENCHMARK_PID=$!

# Monitor VmHWM (High Water Mark - peak RSS) while process is running
MAX_RSS=0
while kill -0 "$BENCHMARK_PID" 2>/dev/null; do
    if [ -f "/proc/$BENCHMARK_PID/status" ]; then
        # VmHWM is the peak RSS maintained by kernel
        current_rss=$(grep "^VmHWM:" "/proc/$BENCHMARK_PID/status" 2>/dev/null | awk '{print $2}')
        if [ -n "$current_rss" ] && [ "$current_rss" -gt "$MAX_RSS" ]; then
            MAX_RSS=$current_rss
        fi
    fi
    sleep 0.01
done

# Wait for benchmark to complete and get exit code
wait $BENCHMARK_PID
BENCHMARK_EXIT_CODE=$?

# Get final VmHWM (read quickly before /proc entry is cleaned up)
if [ -f "/proc/$BENCHMARK_PID/status" ]; then
    final_rss=$(grep "^VmHWM:" "/proc/$BENCHMARK_PID/status" 2>/dev/null | awk '{print $2}')
    if [ -n "$final_rss" ] && [ "$final_rss" -gt "$MAX_RSS" ]; then
        MAX_RSS=$final_rss
    fi
fi

if [ $BENCHMARK_EXIT_CODE -ne 0 ]; then
    exit $BENCHMARK_EXIT_CODE
fi

# Display memory statistics
echo ""
echo "=========================================="
echo "Memory Usage Statistics"
echo "=========================================="
if [ -n "$MAX_RSS" ] && [ "$MAX_RSS" -gt 0 ]; then
    MAX_RSS_MB=$((MAX_RSS / 1024))
    echo "Maximum resident set size (RSS): ${MAX_RSS} KB (${MAX_RSS_MB} MB)"
else
    echo "Warning: Could not determine maximum memory usage"
fi

